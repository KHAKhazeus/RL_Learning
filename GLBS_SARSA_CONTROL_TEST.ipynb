{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#initialize\n",
    "qvalue = np.zeros([16,4])\n",
    "evalue = np.zeros([16,4])\n",
    "\n",
    "#slippery\n",
    "# env = gym.make('FrozenLake-v0')\n",
    "\n",
    "#non-slippery\n",
    "from gym.envs.registration import register\n",
    "register(\n",
    "    id='FrozenLakeNotSlippery-v0',\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
    "    max_episode_steps=100,\n",
    "    reward_threshold=0.8196, # optimum = .8196, changing this seems have no influence\n",
    ")\n",
    "env = gym.make(\"FrozenLakeNotSlippery-v0\")\n",
    "\n",
    "#hyperparameters\n",
    "alphaLearningRate = 0.3\n",
    "faresightLambda = 0.95\n",
    "decayRate = 0.0\n",
    "decay_rate_of_epsilon = 0.001\n",
    "max_epsilon = 1.0\n",
    "min_epsilon = 0.00001 \n",
    "\n",
    "#record score\n",
    "score = []\n",
    "\n",
    "def choose_action(state, epsilon):\n",
    "    if random.random() >= epsilon:\n",
    "        return np.argmax(qvalue[state])\n",
    "    else:\n",
    "        return random.randrange(4)\n",
    "\n",
    "def SARSAcontrol():\n",
    "    epsilon = 1.0\n",
    "    for i in range(20000):\n",
    "        previousState = env.reset()\n",
    "        previousAction = choose_action(previousState, epsilon)\n",
    "        evalue = np.zeros([16,4])\n",
    "        score = []\n",
    "        done = False\n",
    "        while not done:\n",
    "            steps = 0\n",
    "            currentState, reward, done, info = env.step(previousAction)\n",
    "            steps += 1\n",
    "            currentAction = choose_action(currentState, epsilon)\n",
    "            error = reward + faresightLambda * qvalue[currentState][currentAction] \\\n",
    "                - qvalue[previousState][previousAction]\n",
    "            evalue[previousState][previousAction] += 1\n",
    "            \n",
    "            nonZeroes = np.transpose(np.nonzero(evalue))\n",
    "            for nonZeroe in nonZeroes:\n",
    "                row = nonZeroe[0]\n",
    "                column = nonZeroe[1]\n",
    "                qvalue[row][column] += alphaLearningRate * evalue[row][column] * error\n",
    "            \n",
    "            evalue *= decayRate * faresightLambda\n",
    "            \n",
    "            \n",
    "            previousState = currentState\n",
    "            previousAction = currentAction\n",
    "        epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate_of_epsilon*i)\n",
    "                \n",
    "    print(\"training end\")\n",
    "    print(qvalue)\n",
    "    \n",
    "def evaluation():\n",
    "    score = []\n",
    "    done = False\n",
    "    for i in range(10000):\n",
    "        observation = env.reset()\n",
    "        while True:\n",
    "            action = choose_action(observation, 0)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            if done:\n",
    "                score.append(reward)\n",
    "                break\n",
    "    \n",
    "    print(\"accuracy: {}\".format(np.mean(score)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training end\n",
      "[[0.59628938 0.77378094 0.54002364 0.58100452]\n",
      " [0.54321918 0.         0.26026425 0.30348757]\n",
      " [0.34614753 0.16257388 0.08793539 0.20285719]\n",
      " [0.13943466 0.         0.05167362 0.05246588]\n",
      " [0.65781859 0.81450625 0.         0.57031194]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.89672656 0.         0.17839505]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.64936244 0.         0.857375   0.57724564]\n",
      " [0.71768466 0.9025     0.712975   0.        ]\n",
      " [0.83633485 0.95       0.         0.7900671 ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.88346659 0.95       0.83040634]\n",
      " [0.89166222 0.9497491  1.         0.87916188]\n",
      " [0.         0.         0.         0.        ]]\n",
      "accuracy: 1.0\n",
      "training end\n",
      "[[0.62154908 0.58763485 0.77378094 0.62434858]\n",
      " [0.64238321 0.         0.81450625 0.59464561]\n",
      " [0.57002464 0.857375   0.5721133  0.64435625]\n",
      " [0.58006389 0.         0.40733216 0.44950603]\n",
      " [0.3285734  0.38414384 0.         0.63445106]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.9025     0.         0.62015331]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.59676427 0.         0.59190885 0.49179661]\n",
      " [0.70168911 0.90249268 0.80783051 0.        ]\n",
      " [0.856059   0.95       0.         0.84214724]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.78309418 0.95       0.81232538]\n",
      " [0.90239265 0.94999987 1.         0.88796569]\n",
      " [0.         0.         0.         0.        ]]\n",
      "accuracy: 1.0\n",
      "training end\n",
      "[[0.57703197 0.77378094 0.52847675 0.53074131]\n",
      " [0.53324028 0.         0.46821125 0.48212229]\n",
      " [0.47894225 0.40143603 0.46401769 0.45087368]\n",
      " [0.46851449 0.         0.42505999 0.4541813 ]\n",
      " [0.55130115 0.81450625 0.         0.56680233]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.85567808 0.         0.54750952]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.59917413 0.         0.857375   0.64125442]\n",
      " [0.7715958  0.71290407 0.9025     0.        ]\n",
      " [0.83272843 0.95       0.         0.74482548]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.89783659 0.9499844  0.72511617]\n",
      " [0.89737453 0.94997817 1.         0.89608424]\n",
      " [0.         0.         0.         0.        ]]\n",
      "accuracy: 1.0\n",
      "training end\n",
      "[[0.55300474 0.77378094 0.50334635 0.56094634]\n",
      " [0.58338162 0.         0.42433837 0.42473359]\n",
      " [0.44208796 0.39335073 0.41190866 0.40562929]\n",
      " [0.41492284 0.         0.35201912 0.42177664]\n",
      " [0.63529205 0.81450625 0.         0.55623674]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.87744418 0.         0.49625681]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.69843708 0.         0.857375   0.56265789]\n",
      " [0.6648356  0.9025     0.63175    0.        ]\n",
      " [0.80852465 0.95       0.         0.81030357]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.90183579 0.95       0.80127157]\n",
      " [0.89121207 0.94999071 1.         0.9003619 ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "accuracy: 1.0\n",
      "training end\n",
      "[[0.62895096 0.77378094 0.55726502 0.53354253]\n",
      " [0.59671878 0.         0.31675037 0.3517759 ]\n",
      " [0.36926074 0.24787967 0.24697154 0.27218304]\n",
      " [0.24895863 0.         0.24603139 0.25598067]\n",
      " [0.67119777 0.81450625 0.         0.60005047]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.86699828 0.         0.34579444]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.58150643 0.         0.857375   0.67432113]\n",
      " [0.73283654 0.9025     0.63175    0.        ]\n",
      " [0.82037911 0.95       0.         0.79378167]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.89778365 0.95       0.83630005]\n",
      " [0.8891848  0.94991785 1.         0.89936298]\n",
      " [0.         0.         0.         0.        ]]\n",
      "accuracy: 1.0\n",
      "training end\n",
      "[[0.5371412  0.77378094 0.51271921 0.58234849]\n",
      " [0.43659963 0.         0.58850543 0.40467739]\n",
      " [0.45940601 0.69899435 0.2574621  0.41854761]\n",
      " [0.34652777 0.         0.33055081 0.25897723]\n",
      " [0.58722534 0.81450625 0.         0.58446969]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.9022225  0.         0.53161877]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.63853254 0.         0.857375   0.66387881]\n",
      " [0.70235174 0.9025     0.63175    0.        ]\n",
      " [0.84071268 0.95       0.         0.85511073]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.8886727  0.95       0.83087835]\n",
      " [0.90009187 0.94999987 1.         0.88831637]\n",
      " [0.         0.         0.         0.        ]]\n",
      "accuracy: 1.0\n",
      "training end\n",
      "[[0.57120328 0.77378094 0.54133652 0.55138096]\n",
      " [0.47863461 0.         0.81439922 0.47712096]\n",
      " [0.54899141 0.857375   0.60017083 0.64384541]\n",
      " [0.69576966 0.         0.27590208 0.36397725]\n",
      " [0.54267244 0.81450625 0.         0.59958279]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.9025     0.         0.66696705]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.60934121 0.         0.857375   0.62322258]\n",
      " [0.61619743 0.9025     0.63175    0.        ]\n",
      " [0.8214658  0.95       0.         0.84460037]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.89757598 0.95       0.81703721]\n",
      " [0.89173517 0.95       1.         0.89491714]\n",
      " [0.         0.         0.         0.        ]]\n",
      "accuracy: 1.0\n",
      "training end\n",
      "[[0.61859299 0.77378094 0.59304245 0.62180605]\n",
      " [0.6545916  0.         0.25669707 0.44139098]\n",
      " [0.25723743 0.03854737 0.11445798 0.19797468]\n",
      " [0.11463437 0.         0.09707661 0.11078993]\n",
      " [0.61412528 0.81450625 0.         0.56122714]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.89810427 0.         0.18500764]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.57833698 0.         0.857375   0.60586865]\n",
      " [0.74968858 0.71212573 0.9025     0.        ]\n",
      " [0.84201421 0.95       0.         0.84469688]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.86888646 0.9497111  0.69576106]\n",
      " [0.89575389 0.94945875 1.         0.7112106 ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "accuracy: 1.0\n",
      "training end\n",
      "[[0.65763455 0.77378094 0.57861129 0.57976282]\n",
      " [0.58659078 0.         0.44979688 0.4415866 ]\n",
      " [0.46296557 0.41959351 0.44226573 0.43431086]\n",
      " [0.44299774 0.         0.21123174 0.21772293]\n",
      " [0.56337448 0.81450625 0.         0.60438263]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.90161122 0.         0.64079104]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.68726382 0.         0.857375   0.58838986]\n",
      " [0.74968532 0.712975   0.9025     0.        ]\n",
      " [0.80946827 0.95       0.         0.85543947]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.85849767 0.95       0.6819884 ]\n",
      " [0.90014758 0.94904457 1.         0.88869306]\n",
      " [0.         0.         0.         0.        ]]\n",
      "accuracy: 1.0\n",
      "training end\n",
      "[[0.53040766 0.57301258 0.77378094 0.51104248]\n",
      " [0.56667902 0.         0.81450625 0.62163013]\n",
      " [0.5581696  0.857375   0.54891991 0.6485668 ]\n",
      " [0.55318804 0.         0.36410456 0.5161976 ]\n",
      " [0.28863926 0.25909185 0.         0.62722581]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.9025     0.         0.70635917]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.24780463 0.         0.24988119 0.19259045]\n",
      " [0.32434692 0.89935575 0.46953308 0.        ]\n",
      " [0.8483367  0.95       0.         0.82167958]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.8537279  0.94997022 0.49325306]\n",
      " [0.90072702 0.94885253 1.         0.882676  ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "for batch in range(10):\n",
    "    SARSAcontrol()\n",
    "    evaluation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
